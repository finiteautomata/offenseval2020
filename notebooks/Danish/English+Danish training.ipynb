{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Danish multilingual Analysis\n",
    "\n",
    "In this notebook we will look at the errors that our model performs in zero-shot mode.\n",
    "\n",
    "We will use a model trained on OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from datetime import datetime\n",
    "import fire\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchtext import data\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    AdamW, BertForSequenceClassification, BertTokenizer,\n",
    "    get_constant_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from offenseval.nn import (\n",
    "    Tokenizer,\n",
    "    train, evaluate, train_cycle, save_model, load_model, evaluate_dataset\n",
    ")\n",
    "from offenseval.datasets import datasets\n",
    "\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_colwidth = 300\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fields and some other boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from offenseval.datasets import datasets, build_dataset\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "bert_name = \"bert-base-multilingual-cased\"\n",
    "bert_model = BertModel.from_pretrained(bert_name)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_token_idx = bert_tokenizer.cls_token_id\n",
    "eos_token_idx = bert_tokenizer.sep_token_id\n",
    "pad_token_idx = bert_tokenizer.pad_token_id\n",
    "unk_token_idx = bert_tokenizer.unk_token_id\n",
    "\n",
    "# Trying to cut this down to check if this improves memory usage\n",
    "\n",
    "tokenizer = Tokenizer(bert_tokenizer)\n",
    "\n",
    "ID = data.Field(sequential=False, use_vocab=False)\n",
    "# All these arguments are because these are really floats\n",
    "# See https://github.com/pytorch/text/issues/78#issuecomment-541203609\n",
    "SUBTASK_A = data.LabelField()\n",
    "\n",
    "TEXT = data.Field(\n",
    "    tokenize=tokenizer.tokenize,\n",
    "    include_lengths = True,\n",
    "    use_vocab=False,\n",
    "    batch_first = True,\n",
    "    preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "    init_token = init_token_idx,\n",
    "    eos_token = eos_token_idx,\n",
    "    pad_token = pad_token_idx,\n",
    "    unk_token = unk_token_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13240 English tweets\n",
      "There are 2368 Danish tweets\n",
      "There are 25021 Turkish tweets\n"
     ]
    }
   ],
   "source": [
    "from offenseval.datasets import datasets, build_dataset, build_examples\n",
    "\n",
    "fields = {\n",
    "    \"id\": ('id', ID),\n",
    "    \"tweet\": ('text', TEXT),\n",
    "    \"subtask_a\": (\"subtask_a\", SUBTASK_A)\n",
    "}\n",
    "\n",
    "df_train_en = pd.read_table(datasets[\"olid\"][\"train\"])\n",
    "df_train_da = pd.read_table(datasets[\"danish\"][\"train\"])\n",
    "df_train_tr = pd.read_table(datasets[\"turkish\"][\"train\"])\n",
    "\n",
    "#df_train_en = df_train_en.sample(df_train_da.shape[0])\n",
    "\n",
    "train_en_examples = build_examples(df_train_en, fields)\n",
    "train_da_examples = build_examples(df_train_da, fields)\n",
    "train_tr_examples = build_examples(df_train_tr, fields)\n",
    "\n",
    "\n",
    "print(f\"There are {df_train_en.shape[0]} English tweets\")\n",
    "print(f\"There are {df_train_da.shape[0]} Danish tweets\")\n",
    "print(f\"There are {df_train_tr.shape[0]} Turkish tweets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = train_en_examples + train_da_examples\n",
    "\n",
    "train_dataset = data.Dataset(examples, fields.values())\n",
    "dev_dataset = build_dataset(datasets[\"danish\"][\"dev\"], fields)\n",
    "\n",
    "\n",
    "SUBTASK_A.build_vocab(dev_dataset)\n",
    "assert SUBTASK_A.vocab.itos == [\"NOT\", \"OFF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building iterators\n"
     ]
    }
   ],
   "source": [
    "print(\"Building iterators\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_it, dev_it = data.BucketIterator.splits(\n",
    "    (train_dataset, dev_dataset), batch_size=BATCH_SIZE, device=device,\n",
    "    sort_key = lambda x: len(x.text), sort_within_batch = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from offenseval.nn import create_criterion\n",
    "from offenseval.nn.models import BertSeqModel\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "model = BertSeqModel(bert_model, dropout=0.15).to(device)\n",
    "epochs = 10\n",
    "\n",
    "criterion = create_criterion(device)#, weight_with=train_dataset)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "num_training_steps = epochs * len(train_it)\n",
    "num_warmup_steps = num_training_steps // 10\n",
    "warmup_proportion = float(num_warmup_steps) / float(num_training_steps)  # 0.1\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct dataset for better visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074c613645354a45b6d020d07af7877e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2718b7beae3644ca90ae37e48cc3ac1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=488.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.551 Acc: 72.04%\n",
      "Val.Loss: 0.325 Acc: 88.85% Macro F1 0.646 (P 0.353 - N 0.939)\n",
      "Best model so far (Loss: 0.325 Acc: 88.85% Macro F1 0.646 (P 0.353 - N 0.939)) saved at ../../models/bert_cased.en+da.pt\n",
      "\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5f62dda8b5439ca8816c4eff11631f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=488.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.429 Acc: 80.48%\n",
      "Val.Loss: 0.274 Acc: 90.71% Macro F1 0.757 (P 0.567 - N 0.948)\n",
      "Best model so far (Loss: 0.274 Acc: 90.71% Macro F1 0.757 (P 0.567 - N 0.948)) saved at ../../models/bert_cased.en+da.pt\n",
      "\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0942db1a694d0ca2b2c0aa83e46574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=488.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.358 Acc: 84.53%\n",
      "Val.Loss: 0.305 Acc: 88.85% Macro F1 0.756 (P 0.577 - N 0.936)\n",
      "\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73fd266d5aad4249b2299c29a0601902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=488.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.297 Acc: 87.63%\n",
      "Val.Loss: 0.301 Acc: 90.71% Macro F1 0.776 (P 0.604 - N 0.947)\n",
      "Best model so far (Loss: 0.301 Acc: 90.71% Macro F1 0.776 (P 0.604 - N 0.947)) saved at ../../models/bert_cased.en+da.pt\n",
      "\n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a606e91b234a1493306d2e0354dd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=488.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.239 Acc: 90.71%\n",
      "Val.Loss: 0.341 Acc: 91.72% Macro F1 0.787 (P 0.620 - N 0.954)\n",
      "Best model so far (Loss: 0.341 Acc: 91.72% Macro F1 0.787 (P 0.620 - N 0.954)) saved at ../../models/bert_cased.en+da.pt\n",
      "\n",
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807a214c9fad40f7b08f64731f80750d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=488.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.195 Acc: 92.75%\n",
      "Val.Loss: 0.390 Acc: 91.05% Macro F1 0.769 (P 0.589 - N 0.950)\n",
      "\n",
      "\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b20ad2fb6446f9bc5c7a3f92491d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=488.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.160 Acc: 94.43%\n",
      "Val.Loss: 0.400 Acc: 90.20% Macro F1 0.759 (P 0.574 - N 0.945)\n",
      "\n",
      "\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de47c484595407f9f8e79e71363ffc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=488.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.136 Acc: 95.63%\n",
      "Val.Loss: 0.453 Acc: 90.37% Macro F1 0.762 (P 0.578 - N 0.946)\n",
      "\n",
      "\n",
      "Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc6ceaad25348efa8281b8d9b90ec01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=488.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.116 Acc: 96.16%\n",
      "Val.Loss: 0.478 Acc: 90.37% Macro F1 0.759 (P 0.571 - N 0.946)\n",
      "\n",
      "\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c5c2166a6c4c6c955c3be548e9479d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=488.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.097 Acc: 97.03%\n",
      "Val.Loss: 0.496 Acc: 90.20% Macro F1 0.756 (P 0.567 - N 0.945)\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "from offenseval.nn import train_cycle\n",
    "\n",
    "def get_target(batch):\n",
    "    return batch.subtask_a.double()\n",
    "\n",
    "output_path = \"../../models/bert_cased.en+da.pt\"\n",
    "\n",
    "train_cycle(\n",
    "    model, optimizer, criterion, scheduler,\n",
    "    train_it, dev_it, epochs, get_target=get_target, monitor=\"f1\",\n",
    "    model_path=output_path, early_stopping_tolerance=5, ncols=700\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(output_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'EvaluationReport' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9352a19b8c20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtask_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Val Loss: {loss:.3f}  Acc: {acc*100:.2f}% Macro F1: {f1:.3f} Pos F1 {pos_f1:.3f} Neg F1 {neg_f1:.3f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'EvaluationReport' object is not iterable"
     ]
    }
   ],
   "source": [
    "loss, acc, f1, pos_f1, neg_f1 = evaluate(model, dev_it, criterion, get_target=lambda batch: batch.subtask_a)\n",
    "\n",
    "print(f'Val Loss: {loss:.3f}  Acc: {acc*100:.2f}% Macro F1: {f1:.3f} Pos F1 {pos_f1:.3f} Neg F1 {neg_f1:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, TEXT, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
