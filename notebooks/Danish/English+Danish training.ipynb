{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Danish multilingual Analysis\n",
    "\n",
    "In this notebook we will look at the errors that our model performs in zero-shot mode.\n",
    "\n",
    "We will use a model trained on OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from datetime import datetime\n",
    "import fire\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchtext import data\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    AdamW, BertForSequenceClassification, BertTokenizer,\n",
    "    get_constant_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from offenseval.nn import (\n",
    "    Tokenizer,\n",
    "    train, evaluate, train_cycle, save_model, load_model, evaluate_dataset\n",
    ")\n",
    "from offenseval.datasets import datasets\n",
    "\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_colwidth = 300\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fields and some other boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from offenseval.datasets import datasets, build_dataset\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "bert_name = \"bert-base-multilingual-cased\"\n",
    "bert_model = BertModel.from_pretrained(bert_name)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_token_idx = bert_tokenizer.cls_token_id\n",
    "eos_token_idx = bert_tokenizer.sep_token_id\n",
    "pad_token_idx = bert_tokenizer.pad_token_id\n",
    "unk_token_idx = bert_tokenizer.unk_token_id\n",
    "\n",
    "# Trying to cut this down to check if this improves memory usage\n",
    "\n",
    "tokenizer = Tokenizer(bert_tokenizer)\n",
    "\n",
    "ID = data.Field(sequential=False, use_vocab=False)\n",
    "# All these arguments are because these are really floats\n",
    "# See https://github.com/pytorch/text/issues/78#issuecomment-541203609\n",
    "SUBTASK_A = data.LabelField()\n",
    "\n",
    "TEXT = data.Field(\n",
    "    tokenize=tokenizer.tokenize,\n",
    "    include_lengths = True,\n",
    "    use_vocab=False,\n",
    "    batch_first = True,\n",
    "    preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "    init_token = init_token_idx,\n",
    "    eos_token = eos_token_idx,\n",
    "    pad_token = pad_token_idx,\n",
    "    unk_token = unk_token_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13240 English tweets\n",
      "There are 2368 Danish tweets\n",
      "There are 25021 Turkish tweets\n"
     ]
    }
   ],
   "source": [
    "from offenseval.datasets import datasets, build_dataset, build_examples\n",
    "\n",
    "fields = {\n",
    "    \"id\": ('id', ID),\n",
    "    \"tweet\": ('text', TEXT),\n",
    "    \"subtask_a\": (\"subtask_a\", SUBTASK_A)\n",
    "}\n",
    "\n",
    "df_train_en = pd.read_table(datasets[\"olid\"][\"train\"])\n",
    "df_train_da = pd.read_table(datasets[\"danish\"][\"train\"])\n",
    "df_train_tr = pd.read_table(datasets[\"turkish\"][\"train\"])\n",
    "\n",
    "\n",
    "#df_train_en = df_train_en.sample(df_train_da.shape[0])\n",
    "\n",
    "train_en_examples = build_examples(df_train_en, fields)\n",
    "train_da_examples = build_examples(df_train_da, fields)\n",
    "train_tr_examples = build_examples(df_train_tr, fields)\n",
    "\n",
    "\n",
    "print(f\"There are {df_train_en.shape[0]} English tweets\")\n",
    "print(f\"There are {df_train_da.shape[0]} Danish tweets\")\n",
    "print(f\"There are {df_train_tr.shape[0]} Turkish tweets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = train_en_examples + train_da_examples\n",
    "\n",
    "train_dataset = data.Dataset(examples, fields.values())\n",
    "dev_dataset = build_dataset(datasets[\"danish\"][\"dev\"], fields)\n",
    "\n",
    "\n",
    "SUBTASK_A.build_vocab(dev_dataset)\n",
    "assert SUBTASK_A.vocab.itos == [\"NOT\", \"OFF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building iterators\n"
     ]
    }
   ],
   "source": [
    "print(\"Building iterators\")\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_it, dev_it = data.BucketIterator.splits(\n",
    "    (train_dataset, dev_dataset), batch_size=BATCH_SIZE, device=device,\n",
    "    sort_key = lambda x: len(x.text), sort_within_batch = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from offenseval.nn import create_criterion\n",
    "from offenseval.nn.models import BertSeqModel\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "model = BertSeqModel(bert_model, dropout=0.10).to(device)\n",
    "epochs = 10\n",
    "\n",
    "criterion = create_criterion(device)# weight_with=train_dataset)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_training_steps = epochs * len(train_it)\n",
    "num_warmup_steps = num_training_steps // 10\n",
    "warmup_proportion = float(num_warmup_steps) / float(num_training_steps)  # 0.1\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct dataset for better visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e9c4587c384e78b3ccfe2bd53b67ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=10.0), HTML(value='')), layout=Layout(dis…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e1a9ecbff144b0a31f3a109014c1b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1951.0), HTML(value='')), layout=Layout(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.339 Acc: 89.45%\n",
      "Val.Loss: 0.304 Acc: 90.88% Macro F1 0.746 (P 0.542 - N 0.949)\n",
      "Best model so far (Loss: 0.304 Acc: 90.88% Macro F1 0.746 (P 0.542 - N 0.949)) saved at ../../models/bert_cased.en+da.pt\n",
      "\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f989082ccf924ef7a8f92d201e478946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1951.0), HTML(value='')), layout=Layout(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.465 Acc: 81.03%\n",
      "Val.Loss: 0.283 Acc: 91.22% Macro F1 0.784 (P 0.618 - N 0.950)\n",
      "Best model so far (Loss: 0.283 Acc: 91.22% Macro F1 0.784 (P 0.618 - N 0.950)) saved at ../../models/bert_cased.en+da.pt\n",
      "\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d08f948631c40e9964d7238763924c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1951.0), HTML(value='')), layout=Layout(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.403 Acc: 84.51%\n",
      "Val.Loss: 0.337 Acc: 89.86% Macro F1 0.754 (P 0.565 - N 0.943)\n",
      "\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c9d8d678ad428ba82df269d5450b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1951.0), HTML(value='')), layout=Layout(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.364 Acc: 87.31%\n",
      "Val.Loss: 0.375 Acc: 90.54% Macro F1 0.744 (P 0.541 - N 0.947)\n",
      "\n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610e2e38ecd24b8da88d67fe48481ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1951.0), HTML(value='')), layout=Layout(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.309 Acc: 90.74%\n",
      "Val.Loss: 0.385 Acc: 90.71% Macro F1 0.754 (P 0.560 - N 0.948)\n",
      "\n",
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9c0b63452c49d2b1e35e0f0d41cdde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1951.0), HTML(value='')), layout=Layout(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.252 Acc: 93.07%\n",
      "Val.Loss: 0.406 Acc: 91.22% Macro F1 0.775 (P 0.600 - N 0.951)\n",
      "\n",
      "\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3040f19f2da94e2991028a88de6490b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=1951.0), HTML(value='')), layout=Layout(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: Loss: 0.196 Acc: 95.30%\n",
      "Val.Loss: 0.424 Acc: 91.05% Macro F1 0.778 (P 0.607 - N 0.949)\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "from offenseval.nn import train_cycle\n",
    "\n",
    "def get_target(batch):\n",
    "    return batch.subtask_a.double()\n",
    "\n",
    "output_path = \"../../models/bert_cased.en+da.pt\"\n",
    "\n",
    "train_cycle(\n",
    "    model, optimizer, criterion, scheduler, \n",
    "    train_it, dev_it, epochs, get_target=get_target, monitor=\"f1\",\n",
    "    model_path=output_path, early_stopping_tolerance=5, ncols=700\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(output_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.283 Acc: 91.22% Macro F1 0.784 (P 0.618 - N 0.950)\n"
     ]
    }
   ],
   "source": [
    "report = evaluate(\n",
    "    model, \n",
    "    dev_it, \n",
    "    criterion, \n",
    "    get_target=lambda batch: batch.subtask_a)\n",
    "\n",
    "print(f'Val {report}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../../models/bert_cased.en+da.pt\n",
      "Vocab saved to ../../models/bert_cased.en+da.vocab.pkl\n"
     ]
    }
   ],
   "source": [
    "save_model(model, TEXT, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
