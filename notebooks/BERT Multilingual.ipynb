{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with Multilingual BERT\n",
    "\n",
    "Let's first train a model in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "\n",
    "init_token = tokenizer.cls_token\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "init_token_idx = tokenizer.cls_token_id\n",
    "eos_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id\n",
    "\n",
    "# Trying to cut this down to check if this improves memory usage\n",
    "max_input_length = 128 #tokenizer.max_len_single_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "\n",
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length]\n",
    "    return tokens\n",
    "\n",
    "TEXT = data.Field(\n",
    "    #tokenize = 'spacy', \n",
    "    #tokenizer_language=\"es\",\n",
    "    tokenize=tokenize_and_cut,\n",
    "    include_lengths = True,\n",
    "    use_vocab=False,\n",
    "    batch_first = True,\n",
    "    preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "    init_token = init_token_idx,\n",
    "    eos_token = eos_token_idx,\n",
    "    pad_token = pad_token_idx,\n",
    "    unk_token = unk_token_idx\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train instances: 90754\n",
      "Dev   instances: 13240\n"
     ]
    }
   ],
   "source": [
    "ID = data.Field(sequential=False, use_vocab=False)\n",
    "# All these arguments are because these are really floats\n",
    "# See https://github.com/pytorch/text/issues/78#issuecomment-541203609\n",
    "AVG = data.LabelField(dtype = torch.float, use_vocab=False, preprocessing=float)\n",
    "STD = data.LabelField(dtype = torch.float, use_vocab=False, preprocessing=float)\n",
    "SUBTASK_A = data.LabelField()\n",
    "\n",
    "train_dataset = data.TabularDataset(\n",
    "    \"../data/English/task_a_distant.sample.tsv\",\n",
    "    format=\"tsv\", skip_header=True,\n",
    "    fields=[(\"id\", ID), (\"text\", TEXT), (\"avg\", AVG), (\"std\", STD)],\n",
    ")\n",
    "\n",
    "dev_dataset = data.TabularDataset(\n",
    "    \"../data/olid/olid-training-v1.0.tsv\",\n",
    "    format=\"tsv\", skip_header=True,\n",
    "    fields=[(\"id\", ID), (\"text\", TEXT), \n",
    "            (\"subtask_a\", SUBTASK_A), (\"subtask_b\", None), (\"subtask_c\", None)],\n",
    "    \n",
    ")\n",
    "\n",
    "print(f\"Train instances: {len(train_dataset)}\")\n",
    "\n",
    "print(f\"Dev   instances: {len(dev_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build vocabulary for label field. Can we just say 0 -> NOT (Offensive) 1 -> OFF? \n",
    "\n",
    "I don't know, just to make sure add the assertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBTASK_A.build_vocab(dev_dataset)\n",
    "\n",
    "assert SUBTASK_A.vocab.itos == [\"NOT\", \"OFF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "bert = BertModel.from_pretrained('bert-base-multilingual-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['¬ø', 'lo', 'creer', '##as', ',', 'aria', '##dna', '?', 'dijo', 'tese', '##o', '.', 'el', 'mino', '##tau', '##ro', 'apenas', 'se', 'defend', '##io', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 21, 768]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(\"¬øLo creer√°s, Ariadna? dijo Teseo. El minotauro apenas se defendi√≥.\")\n",
    "\n",
    "token_ids = torch.LongTensor(tokenizer.convert_tokens_to_ids(tokens))\n",
    "# I need to reshape it before BERT consumes it\n",
    "# (batch_len, seq_len)... in this case batch_len == 1\n",
    "print(tokenizer.convert_ids_to_tokens(token_ids))\n",
    "last_hidden, clf = bert(token_ids.view(1, -1))\n",
    "\n",
    "last_hidden.shape, clf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BERTGRUSentiment(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 n_layers=1, \n",
    "                 bidirectional=False,\n",
    "                 finetune_bert=False,\n",
    "                 dropout=0.2):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        \n",
    "        self.finetune_bert = finetune_bert\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers = n_layers,\n",
    "                          bidirectional = bidirectional,\n",
    "                          batch_first = True,\n",
    "                          dropout = 0 if n_layers < 2 else dropout)\n",
    "    \n",
    "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):    \n",
    "        #text = [batch size, sent len]\n",
    "        \n",
    "        if not self.finetune_bert:\n",
    "            with torch.no_grad():\n",
    "                embedded = self.bert(text)[0]\n",
    "            #embedded = [batch size, sent len, emb dim]\n",
    "        else:\n",
    "            embedded = self.bert(text)[0]\n",
    "        _, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #hidden = [n layers * n directions, batch size, emb dim]\n",
    "        \n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "                \n",
    "        #hidden = [batch size, hid dim]\n",
    "        \n",
    "        output = self.out(hidden)\n",
    "        \n",
    "        #output = [batch size, out dim]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for name, param in model.named_parameters():                \n",
    "#    if name.startswith('bert'):\n",
    "#        param.requires_grad = False\n",
    "        \n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "train_it, dev_it = data.BucketIterator.splits(\n",
    "    (train_dataset, dev_dataset), batch_size=BATCH_SIZE, device=device,\n",
    "    sort_key = lambda x: len(x.text), sort_within_batch = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, max_grad_norm=None):\n",
    "    \"\"\"\n",
    "    Trains the model for one full epoch\n",
    "    \"\"\"\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        text, lens = batch.text\n",
    "\n",
    "        predictions = model(text)\n",
    "        \n",
    "        target = 1.0 * (batch.avg > 0.6) \n",
    "        \n",
    "        loss = criterion(predictions.squeeze(1), target)\n",
    "        \n",
    "        prob_predictions = torch.sigmoid(predictions)\n",
    "        preds = torch.round(prob_predictions).detach().cpu()\n",
    "        acc = accuracy_score(preds, target.cpu())\n",
    "\n",
    "        loss.backward()\n",
    "        # Gradient clipping\n",
    "        if max_grad_norm:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            \n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the given iterator\n",
    "    \"\"\"\n",
    "    epoch_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predicted_probas = []\n",
    "        labels = []\n",
    "        for batch in iterator:\n",
    "            text, lens = batch.text\n",
    "            target = batch.subtask_a\n",
    "            \n",
    "            predictions = model(text)\n",
    "            loss = criterion(predictions.squeeze(1), target.float())\n",
    "            \n",
    "            prob_predictions = torch.sigmoid(predictions)\n",
    "\n",
    "            predicted_probas.append(prob_predictions)\n",
    "            labels.append(target.cpu())\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        predicted_probas = torch.cat(predicted_probas).cpu()\n",
    "        labels = torch.cat(labels).cpu()\n",
    "\n",
    "        preds = torch.round(predicted_probas)\n",
    "\n",
    "        pos_f1 = f1_score(labels, preds)\n",
    "        neg_f1 = f1_score(1-labels, 1-preds)\n",
    "        avg_f1 = (pos_f1 + neg_f1) / 2\n",
    "        acc = accuracy_score(labels, preds)\n",
    "\n",
    "    return epoch_loss / len(iterator), acc, avg_f1, pos_f1, neg_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the class weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74886878, 1.50454545])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import compute_class_weight, compute_sample_weight\n",
    "y = []\n",
    "for elem in dev_dataset:\n",
    "    y.append(1*(elem.subtask_a == 'OFF'))\n",
    "    \n",
    "class_weights = compute_class_weight('balanced', [0, 1], y)\n",
    "\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 168,144,641 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.25\n",
    "\n",
    "model = BERTGRUSentiment(\n",
    "    bert,\n",
    "    finetune_bert=False,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([class_weights[1]]))\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=1)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd9bb915e33428eb2a3d605f0c3240e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=20.0), HTML(value='')), layout=Layout(dis‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44164f005384a67b920e49ce52f6a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2837.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model so far (Loss 0.980 - Acc 0.790, F1 0.729) saved at /tmp/bert_model.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ff2416d6ef423c9dfc1b757fe73d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2837.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73dbf83739454326a555c0139b68ccae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2837.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc692564725640e9b80cae14cabdfad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2837.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c41d02d154f40bf8371c1006e9593a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2837.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-ac9e87d2e37c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     train_loss, train_acc = train(\n\u001b[1;32m     19\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-2901f15a542a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, max_grad_norm)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/offenseval2020-HKdlw5Be/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/offenseval2020-HKdlw5Be/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "N_EPOCHS = 12\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "early_stopping_tolerance = 4\n",
    "epochs_without_improvement = 0\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "model_path = f\"/tmp/bert_model.pt\"\n",
    "\n",
    "pbar = tqdm(range(N_EPOCHS), ncols=1000)\n",
    "for epoch in pbar:\n",
    "    epoch_bar = tqdm(train_it)\n",
    "    \n",
    "    train_loss, train_acc = train(\n",
    "        model, epoch_bar, optimizer, criterion,\n",
    "        max_grad_norm=max_grad_norm\n",
    "    )\n",
    "    valid_loss, valid_acc, valid_f1, pos_f1, neg_f1 = evaluate(model, dev_it, criterion)\n",
    "    scheduler.step(valid_loss)\n",
    "    \n",
    "    desc = f'Train: Loss: {train_loss:.3f} Acc: {train_acc*100:.2f}%'\n",
    "    desc += f'\\nVal. Loss: {valid_loss:.3f} Acc: {valid_acc*100:.2f}% F1 {valid_f1:.3f}'\n",
    "    pbar.set_description(desc)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"Best model so far (Loss {best_valid_loss:.3f} - Acc {valid_acc:.3f}, F1 {valid_f1:.3f}) saved at {model_path}\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= early_stopping_tolerance:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.980  Acc: 78.96% Macro F1: 0.729 Pos F1 0.600 Neg F1 0.857\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "loss, acc, f1, pos_f1, neg_f1 = evaluate(model, dev_it, criterion)\n",
    "\n",
    "print(f'Val Loss: {loss:.3f}  Acc: {acc*100:.2f}% Macro F1: {f1:.3f} Pos F1 {pos_f1:.3f} Neg F1 {neg_f1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../models/bert.en-sample.no-ft.mean06.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "I reload the dataframe because it is not possible to retrieve the original text from the examples :-\\ (they are already tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet', 'subtask_a', 'subtask_b', 'subtask_c'], dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev = pd.read_table(\"../data/olid/olid-training-v1.0.tsv\", index_col=0)\n",
    "\n",
    "df_dev.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b41a94f8bb94123ae22387ddaf8f213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=414.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "rows = []\n",
    "for batch in tqdm(dev_it):\n",
    "    text, lens = batch.text\n",
    "    \n",
    "    outs = model(text)\n",
    "    ids = batch.id\n",
    "    labels = batch.subtask_a\n",
    "    probs = torch.sigmoid(outs)\n",
    "    preds = torch.round(probs)\n",
    "    \n",
    "    for tid, label, pred, prob in zip(ids.cpu(), labels.cpu(), preds.cpu(), probs.cpu()):\n",
    "        rows.append({\n",
    "            \"id\": tid.item(),\n",
    "            \"text\": df_dev.loc[tid.item(), \"tweet\"],\n",
    "            \"label\": label.item(),\n",
    "            \"pred\": int(pred.item()),\n",
    "            \"prob\": prob.item()\n",
    "        })\n",
    "        \n",
    "df = pd.DataFrame(rows)\n",
    "df.set_index(\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falsos negativos: 2311\n",
      "Falsos positivos: 475\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred not off</th>\n",
       "      <th>pred off</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not off</th>\n",
       "      <td>8365</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off</th>\n",
       "      <td>2311</td>\n",
       "      <td>2089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred not off  pred off\n",
       "real                           \n",
       "not off          8365       475\n",
       "off              2311      2089"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_pos = df[(df[\"label\"] == 1) & (df[\"pred\"] == 1)].copy()\n",
    "false_neg = df[(df[\"label\"] == 1) & (df[\"pred\"] == 0)].copy()\n",
    "false_neg.sort_values(\"prob\", ascending=True, inplace=True)\n",
    "false_pos = df[(df[\"label\"] == 0) & (df[\"pred\"] == 1)].copy()\n",
    "false_pos.sort_values(\"prob\", ascending=False, inplace=True)\n",
    "true_neg = df[(df[\"label\"] == 0) & (df[\"pred\"] == 0)].copy()\n",
    "\n",
    "conf_matrix = pd.DataFrame([\n",
    "    {\"real\":\"not off\", \"pred not off\": len(true_neg),      \"pred off\": len(false_pos)},\n",
    "    {\"real\":\"off\",     \"pred not off\":     len(false_neg), \"pred off\": len(true_pos)}\n",
    "])\n",
    "\n",
    "conf_matrix.set_index(\"real\", inplace=True)\n",
    "\n",
    "print(\"Falsos negativos: {}\".format(len(false_neg)))\n",
    "print(\"Falsos positivos: {}\".format(len(false_pos)))\n",
    "\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred not off</th>\n",
       "      <th>pred off</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>not off</th>\n",
       "      <td>0.632</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>off</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred not off  pred off\n",
       "real                           \n",
       "not off         0.632     0.036\n",
       "off             0.175     0.158"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "\n",
    "conf_matrix / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terrible recall for offensive tweets. We've got to improve this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@USER @USER @USER @USER You ignored my question, which is crucial to the argument. Once sensible\" gun control is imposed and another shooting occurs, do you truly believe they will not push for further restrictions?\"'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_neg.iloc[0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this really offensive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     @USER @USER @USER @USER You ignored my questio...\n",
       "label                                                    1\n",
       "pred                                                     0\n",
       "prob                                                 0.000\n",
       "Name: 80706, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_neg.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there any error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet        @USER I have you and Kaze- I need more.\n",
       "subtask_a                                        OFF\n",
       "subtask_b                                        TIN\n",
       "subtask_c                                        IND\n",
       "Name: 79079, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.loc[79079]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80706</th>\n",
       "      <td>@USER @USER @USER @USER You ignored my question, which is crucial to the argument. Once sensible\" gun control is imposed and another shooting occurs, do you truly believe they will not push for further restrictions?\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45781</th>\n",
       "      <td>Sean Penn: #MeToo Movement Seeks to ‚ÄòDivide Men and Women‚Äô URL &amp;lt;‚Äî Gotta say‚Ä¶ I stand w/ Jeff Spicoli on this one. URL  #MAGA #WWG1WGA #ConfirmKavanaugh</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31527</th>\n",
       "      <td>@USER He is quite good at faking. Must have done it numerous times</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70844</th>\n",
       "      <td>@USER I was think she jisoo but I‚Äôm Focused I found she is taeyoun</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46424</th>\n",
       "      <td>@USER @USER @USER You should.have tried more, perhaps a BJP or RSS connection could have been fixed\".Masters would be happy Dhanya\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19303</th>\n",
       "      <td>@USER Hallo please find the unroll here: Thread by @USER 1. Moore's failure to deal with the foul smear against him, is a good example of how the new rules could apply. The firs [‚Ä¶]\" #FakeNews #MAGA URL See you soon. ü§ñ\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54306</th>\n",
       "      <td>@USER @USER Hillary? Why is she on the social studies curriculum? Why? Who is she to be in any curriculum?  She is nothing!  I'm shocked that she was in any curriculum, but I am very happy to see that she is OUT!\"  (I am so glad she's nowhere near the @USER</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62156</th>\n",
       "      <td>@USER America will be better off once you retire Flakey Jeff Flake.  Go away.......</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19179</th>\n",
       "      <td>@USER @USER @USER @USER as of right now my only solid position is that the NRA has become far too influential in politics and as a result they have delayed the desire for gun control for about 20 years.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37694</th>\n",
       "      <td>@USER Ok but please understand that I am not one of dubakoor mumtaj dubakoor army. I only support her for certain things. I get what you are saying and I don‚Äôt understand how she has survived from up to this point. For me she is not fit for title winner.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90703</th>\n",
       "      <td>@USER Can we send this piece of üí© to the tower? Wouldn‚Äôt it be nice if we could do as Great Britain once did. I say build the wall and tower at the same time just in time for the Hillary Clinton NONpresidential suite! Hahahahaha</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79122</th>\n",
       "      <td>@USER @USER @USER The Democrats are so desperate all those ppl threatening Sen Collins are from CA. They will do anything to delay or halt confirmation and @USER re-election is on the line she is desperate. The ppl &amp;amp; GOP are quite aware of what is going on.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20648</th>\n",
       "      <td>@USER @USER It's clear that Trump is President and hillary still can't accept that. Too bad 'ause he's there for 6 more years. #MAGA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69106</th>\n",
       "      <td>I got more common sense than all of my followers  :)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53784</th>\n",
       "      <td>@USER @USER I agree he is very intelligent and I like the latest policy of a sovereign wealth fund - something I've long supported. But he just doesn't cut through. Someone like Jo Swinson would get the party more air time imo.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65102</th>\n",
       "      <td>@USER @USER @USER @USER So if Paul Golding turned up for a job at the BBC you'd let him work for them?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36701</th>\n",
       "      <td>@USER Then I see like this and lust over the girl with the long blond hair and the bare midriff and micro-mini and realize she is now 48 years older and could be a great grandmother today! üò± People wonder why I love legs until I show them what I grew up with. URL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42205</th>\n",
       "      <td>@USER @USER #Privilege Laneü§î #MAGA Blvdü§î Good Ole Days Avenueü§î</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24747</th>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USER @USER @USER I dont think so..it would mean he is in trouble.  Dont wish that on anyone.  Isn't that where the Cumm Inn is at?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44067</th>\n",
       "      <td>@USER After watching the entire match and controversy Serena is lucky she didn't get a match misconduct. She is so upset that the ref. Would give her a warning for her coach coaching\" which he even admitted to. The ref did nothing wrong he enforced the rule and Serena did it like it.\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95720</th>\n",
       "      <td>@USER @USER found out the name but I forgot.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55959</th>\n",
       "      <td>Should I try out aikido instead of krav maga? ü§îü§î #aikido #kravmaga</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79079</th>\n",
       "      <td>@USER I have you and Kaze- I need more.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38183</th>\n",
       "      <td>@USER Is that some weird invitation for a treasure hunt where the goal is to find his old ‚Äúdeadname‚Äù? Is it because he feels the need to prove that he is trans? Or because ppl didn‚Äôt care about it enough? Either way I‚Äôm not going to join üòí</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75669</th>\n",
       "      <td>@USER Wtf have I missed here. My account was hacked and just got it back up and running. Somebody care to explain what‚Äôs going on here.  Am I right in saying that the guy who has been playing live saying he is Dash Berlin aka Jeff ??? So what‚Äôs happened ???</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20434</th>\n",
       "      <td>@USER @USER @USER @USER @USER you are indeed an ewu so I won't trade words with you. Anumanu.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42410</th>\n",
       "      <td>@USER @USER Feinstein wanted to delay until after the midterms.  Hopefully the RED wave will wash her into the Atlantic. #MAGA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22728</th>\n",
       "      <td>@USER #StrataData #AI #data #hairball: @USER TDavis touring the application of #Cognitive and #machinelearning techniques to speed #Governance of #data URL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23152</th>\n",
       "      <td>@USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER Followed most patriots already and got the rest appreciate a follow back #MAGA üëç</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85971</th>\n",
       "      <td>@USER Man I hope I don‚Äôt die before Florence hits.. I heard he is going to be a great time!!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                text  \\\n",
       "id                                                                                                                                                                                                                                                                                                     \n",
       "80706                                                                       @USER @USER @USER @USER You ignored my question, which is crucial to the argument. Once sensible\" gun control is imposed and another shooting occurs, do you truly believe they will not push for further restrictions?\"   \n",
       "45781                                                                                                                                     Sean Penn: #MeToo Movement Seeks to ‚ÄòDivide Men and Women‚Äô URL &lt;‚Äî Gotta say‚Ä¶ I stand w/ Jeff Spicoli on this one. URL  #MAGA #WWG1WGA #ConfirmKavanaugh   \n",
       "31527                                                                                                                                                                                                                             @USER He is quite good at faking. Must have done it numerous times   \n",
       "70844                                                                                                                                                                                                                             @USER I was think she jisoo but I‚Äôm Focused I found she is taeyoun   \n",
       "46424                                                                                                                                                            @USER @USER @USER You should.have tried more, perhaps a BJP or RSS connection could have been fixed\".Masters would be happy Dhanya\"   \n",
       "19303                                                                    @USER Hallo please find the unroll here: Thread by @USER 1. Moore's failure to deal with the foul smear against him, is a good example of how the new rules could apply. The firs [‚Ä¶]\" #FakeNews #MAGA URL See you soon. ü§ñ\"   \n",
       "54306                              @USER @USER Hillary? Why is she on the social studies curriculum? Why? Who is she to be in any curriculum?  She is nothing!  I'm shocked that she was in any curriculum, but I am very happy to see that she is OUT!\"  (I am so glad she's nowhere near the @USER   \n",
       "62156                                                                                                                                                                                                            @USER America will be better off once you retire Flakey Jeff Flake.  Go away.......   \n",
       "19179                                                                                     @USER @USER @USER @USER as of right now my only solid position is that the NRA has become far too influential in politics and as a result they have delayed the desire for gun control for about 20 years.   \n",
       "37694                                 @USER Ok but please understand that I am not one of dubakoor mumtaj dubakoor army. I only support her for certain things. I get what you are saying and I don‚Äôt understand how she has survived from up to this point. For me she is not fit for title winner.   \n",
       "90703                                                           @USER Can we send this piece of üí© to the tower? Wouldn‚Äôt it be nice if we could do as Great Britain once did. I say build the wall and tower at the same time just in time for the Hillary Clinton NONpresidential suite! Hahahahaha   \n",
       "79122                          @USER @USER @USER The Democrats are so desperate all those ppl threatening Sen Collins are from CA. They will do anything to delay or halt confirmation and @USER re-election is on the line she is desperate. The ppl &amp; GOP are quite aware of what is going on.   \n",
       "20648                                                                                                                                                           @USER @USER It's clear that Trump is President and hillary still can't accept that. Too bad 'ause he's there for 6 more years. #MAGA   \n",
       "69106                                                                                                                                                                                                                                           I got more common sense than all of my followers  :)   \n",
       "53784                                                            @USER @USER I agree he is very intelligent and I like the latest policy of a sovereign wealth fund - something I've long supported. But he just doesn't cut through. Someone like Jo Swinson would get the party more air time imo.   \n",
       "65102                                                                                                                                                                                         @USER @USER @USER @USER So if Paul Golding turned up for a job at the BBC you'd let him work for them?   \n",
       "36701                        @USER Then I see like this and lust over the girl with the long blond hair and the bare midriff and micro-mini and realize she is now 48 years older and could be a great grandmother today! üò± People wonder why I love legs until I show them what I grew up with. URL   \n",
       "42205                                                                                                                                                                                                                                 @USER @USER #Privilege Laneü§î #MAGA Blvdü§î Good Ole Days Avenueü§î   \n",
       "24747                                                                                                                  @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER I dont think so..it would mean he is in trouble.  Dont wish that on anyone.  Isn't that where the Cumm Inn is at?   \n",
       "44067  @USER After watching the entire match and controversy Serena is lucky she didn't get a match misconduct. She is so upset that the ref. Would give her a warning for her coach coaching\" which he even admitted to. The ref did nothing wrong he enforced the rule and Serena did it like it.\"   \n",
       "95720                                                                                                                                                                                                                                                   @USER @USER found out the name but I forgot.   \n",
       "55959                                                                                                                                                                                                                             Should I try out aikido instead of krav maga? ü§îü§î #aikido #kravmaga   \n",
       "79079                                                                                                                                                                                                                                                        @USER I have you and Kaze- I need more.   \n",
       "38183                                                @USER Is that some weird invitation for a treasure hunt where the goal is to find his old ‚Äúdeadname‚Äù? Is it because he feels the need to prove that he is trans? Or because ppl didn‚Äôt care about it enough? Either way I‚Äôm not going to join üòí   \n",
       "75669                              @USER Wtf have I missed here. My account was hacked and just got it back up and running. Somebody care to explain what‚Äôs going on here.  Am I right in saying that the guy who has been playing live saying he is Dash Berlin aka Jeff ??? So what‚Äôs happened ???   \n",
       "20434                                                                                                                                                                                                  @USER @USER @USER @USER @USER you are indeed an ewu so I won't trade words with you. Anumanu.   \n",
       "42410                                                                                                                                                                 @USER @USER Feinstein wanted to delay until after the midterms.  Hopefully the RED wave will wash her into the Atlantic. #MAGA   \n",
       "22728                                                                                                                                    @USER #StrataData #AI #data #hairball: @USER TDavis touring the application of #Cognitive and #machinelearning techniques to speed #Governance of #data URL   \n",
       "23152                                                                                                         @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER @USER Followed most patriots already and got the rest appreciate a follow back #MAGA üëç   \n",
       "85971                                                                                                                                                                                                   @USER Man I hope I don‚Äôt die before Florence hits.. I heard he is going to be a great time!!   \n",
       "\n",
       "       label  pred  prob  \n",
       "id                        \n",
       "80706      1     0 0.000  \n",
       "45781      1     0 0.000  \n",
       "31527      1     0 0.000  \n",
       "70844      1     0 0.000  \n",
       "46424      1     0 0.000  \n",
       "19303      1     0 0.000  \n",
       "54306      1     0 0.000  \n",
       "62156      1     0 0.000  \n",
       "19179      1     0 0.000  \n",
       "37694      1     0 0.000  \n",
       "90703      1     0 0.000  \n",
       "79122      1     0 0.000  \n",
       "20648      1     0 0.000  \n",
       "69106      1     0 0.000  \n",
       "53784      1     0 0.000  \n",
       "65102      1     0 0.000  \n",
       "36701      1     0 0.000  \n",
       "42205      1     0 0.000  \n",
       "24747      1     0 0.000  \n",
       "44067      1     0 0.000  \n",
       "95720      1     0 0.000  \n",
       "55959      1     0 0.000  \n",
       "79079      1     0 0.000  \n",
       "38183      1     0 0.000  \n",
       "75669      1     0 0.000  \n",
       "20434      1     0 0.000  \n",
       "42410      1     0 0.000  \n",
       "22728      1     0 0.001  \n",
       "23152      1     0 0.001  \n",
       "85971      1     0 0.001  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', None)\n",
    "false_neg.iloc[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
