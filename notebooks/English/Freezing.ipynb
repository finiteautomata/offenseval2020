{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing layers\n",
    "\n",
    "In this notebook we will try to freeze layers and check if that improves performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from datetime import datetime\n",
    "import fire\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchtext import data\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    AdamW, BertForSequenceClassification, BertTokenizer,\n",
    "    get_constant_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from offenseval.nn import (\n",
    "    Tokenizer,\n",
    "    train, evaluate, train_cycle, save_model, load_model, evaluate_dataset\n",
    ")\n",
    "from offenseval.datasets import datasets\n",
    "\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_colwidth = 300\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fields and some other boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from offenseval.datasets import datasets, build_dataset\n",
    "from offenseval.nn import create_bert_fields\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "bert_name = \"bert-base-multilingual-cased\"\n",
    "bert_model = BertModel.from_pretrained(bert_name)\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_name)\n",
    "\n",
    "ID, SUBTASK_A, TEXT = create_bert_fields(bert_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building from langs olid danish turkish arabic greek\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c596bb8364a4a769bed6b3ed4225036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13240.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2540dce94344ae993aaf927b11bbb82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2368.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17370d6e7c8431f8120e7b7d3fe42be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25021.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from offenseval.datasets import datasets, build_datasets, build_examples\n",
    "\n",
    "fields = {\n",
    "    \"id\": ('id', ID),\n",
    "    \"text\": ('text', TEXT),\n",
    "    \"subtask_a\": (\"subtask_a\", SUBTASK_A)\n",
    "}\n",
    "\n",
    "train_dataset, dev_dataset, test_dataset = build_datasets(fields, lang=\"all\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBTASK_A.build_vocab(dev_dataset)\n",
    "assert SUBTASK_A.vocab.itos == [\"NOT\", \"OFF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building iterators\")\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_it, dev_it = data.BucketIterator.splits(\n",
    "    (train_dataset, dev_dataset), batch_size=BATCH_SIZE, device=device,\n",
    "    sort_key = lambda x: len(x.text), sort_within_batch = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from offenseval.nn import create_criterion\n",
    "from offenseval.nn.models import BertSeqModel\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "model = BertSeqModel(bert_model, dropout=0.10).to(device)\n",
    "epochs = 10\n",
    "\n",
    "criterion = create_criterion(device)# weight_with=train_dataset)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "num_training_steps = epochs * len(train_it)\n",
    "num_warmup_steps = num_training_steps // 10\n",
    "warmup_proportion = float(num_warmup_steps) / float(num_training_steps)  # 0.1\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for param in model.bert.embeddings.parameters():\n",
    "#    param.requires_grad = False\n",
    "\n",
    "for i in range(3):\n",
    "    layer = model.bert.encoder.layer[i]\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct dataset for better visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from offenseval.nn import train_cycle\n",
    "\n",
    "def get_target(batch):\n",
    "    return batch.subtask_a.double()\n",
    "\n",
    "output_path = \"../../models/bert_cased.all.freeze.pt\"\n",
    "\n",
    "train_cycle(\n",
    "    model, optimizer, criterion, scheduler, \n",
    "    train_it, dev_it, epochs, get_target=get_target, monitor=\"f1\",\n",
    "    model_path=output_path, early_stopping_tolerance=5, ncols=700\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(output_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = evaluate(\n",
    "    model, \n",
    "    dev_it, \n",
    "    criterion, \n",
    "    get_target=lambda batch: batch.subtask_a)\n",
    "\n",
    "print(f'Val {report}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, TEXT, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
